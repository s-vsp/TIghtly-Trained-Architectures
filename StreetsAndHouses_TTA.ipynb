{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSgrytK-aN5X"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au7w2x8pa8aP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torchvision as tv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "from transformers import ConvNextV2ForImageClassification\n",
        "from transformers.models.convnextv2.modeling_convnextv2 import ConvNextV2Embeddings\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKiwOUwPhN45",
        "outputId": "b2e6007f-c9d5-4e67-8d04-7abb88b60f01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njsA9yP9a6al"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asSt0LgKbHmL"
      },
      "outputs": [],
      "source": [
        " !unzip -q /content/drive/MyDrive/TTA/streetshouses.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giCb02-qZg0b"
      },
      "outputs": [],
      "source": [
        "class StreetAndHousesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, transform=None):\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "        self.file_paths = list()\n",
        "        self.labels = list()\n",
        "\n",
        "        # Real labels\n",
        "        labels_keys = [\"apartment\", \"bath\", \"bed\", \"church\", \\\n",
        "                  \"commercial\", \"din\", \"garage\", \"house\", \"industrial\", \"kitchen\", \"living\", \"retail\", \"roof\"]\n",
        "\n",
        "        LABELS = {key: val for key, val in zip(labels_keys, list(range(len(labels_keys))))}\n",
        "\n",
        "        for file_path in files:\n",
        "          if \"BdIdx\" not in file_path:\n",
        "            label = os.path.basename(file_path).split(\"_\")[0]\n",
        "          else:\n",
        "            label = os.path.basename(file_path).split(\"_\")[-1][:-4]\n",
        "\n",
        "          # Additional cleaning of labels is required\n",
        "          if label == \"apartments\":\n",
        "            label = \"apartment\"\n",
        "          if label == \"garages\":\n",
        "            label = \"garage\"\n",
        "          if label == \"office\":\n",
        "            label = \"officebuilding\"\n",
        "\n",
        "          if label in LABELS.keys():\n",
        "            self.file_paths.append(file_path)\n",
        "            self.labels.append(LABELS[label])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpSQ8H34i1iS"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awt4N46ii5iW"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=(224,224), scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtupuxizUi3f"
      },
      "outputs": [],
      "source": [
        "# Create paths for val, train and test (with shuffling the data)\n",
        "dirs = [os.path.join(\"./streetshouses/kaggle_room_street_data/\", path) for path in os.listdir(\"./streetshouses/kaggle_room_street_data/\")]\n",
        "\n",
        "all_files = []\n",
        "\n",
        "for dir_path in dirs:\n",
        "    files = [os.path.join(dir_path, file) for file in os.listdir(dir_path)]\n",
        "    all_files.extend(files)\n",
        "\n",
        "train_paths, test_paths = train_test_split(all_files, train_size=0.9, random_state=42, shuffle=True)\n",
        "train_paths, val_paths = train_test_split(train_paths, train_size=0.78, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAzPE9jDjMzf"
      },
      "outputs": [],
      "source": [
        "train_ds = StreetAndHousesDataset(files=train_paths, transform=transforms_train)\n",
        "val_ds = StreetAndHousesDataset(files=val_paths, transform=transforms_val)\n",
        "test_ds = StreetAndHousesDataset(files=test_paths, transform=transforms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqT0J1vlcroe"
      },
      "outputs": [],
      "source": [
        "IN_CHANNELS = 3\n",
        "N_CLASSES = 13\n",
        "\n",
        "vgg16_model = tv.models.vgg16(weights=\"IMAGENET1K_V1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKmlZLLFdLzW"
      },
      "outputs": [],
      "source": [
        "for param in vgg16_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO_hm6-lhFWa"
      },
      "outputs": [],
      "source": [
        "# Add on classifier\n",
        "n_inputs = vgg16_model.classifier[6].in_features\n",
        "vgg16_model.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.6),\n",
        "    nn.Linear(256, N_CLASSES), nn.LogSoftmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLPnawYhH2V"
      },
      "outputs": [],
      "source": [
        "vgg16_model = vgg16_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUfUyaDghKNk",
        "outputId": "91aa4220-9ddb-462a-fd1c-8ecbae8d06c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "135,312,717 total parameters.\n",
            "1,052,173 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in vgg16_model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in vgg16_model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi-ARrtwha6I"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 35\n",
        "LEARNING_RATE = 1e-2\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxUlVAHghksI"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(dataset=val_ds, batch_size=BATCH_SIZE)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGnWKj2OhnIX"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(vgg16_model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer, mode=\"max\", factor=0.1, patience=6, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX0lYa1bhqyI"
      },
      "outputs": [],
      "source": [
        "best_val_loss = 1e7\n",
        "train_losses = list()\n",
        "val_losses = list()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Train\n",
        "  vgg16_model.train()\n",
        "  train_loss = 0.0\n",
        "  for batch in tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{EPOCHS}\", ncols=100):\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = vgg16_model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  # Validate\n",
        "  vgg16_model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(val_dl, desc=\"Validation\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = vgg16_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "  lr_scheduler.step(val_loss)\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(vgg16_model.state_dict(), \"/content/drive/MyDrive/checkpoints/vgg16-streetsandhouses.pt\")\n",
        "\n",
        "  train_losses.append(train_loss / len(train_dl))\n",
        "  val_losses.append(val_loss / len(val_dl))\n",
        "\n",
        "  accuracy = 100 * correct_predictions / total_predictions\n",
        "  print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss / len(train_dl):.4f}, Validation Loss: {val_loss / len(val_dl):.4f}, Validation Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAhD5vGlrqoq",
        "outputId": "58a52be9-aea6-47b1-92a1-0c84fe2601c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|████████████████████████████████████████████████████| 141/141 [00:38<00:00,  3.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy = 51.6644%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on Test set\n",
        "vgg16_model.eval()\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dl, desc=\"Testing\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = vgg16_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"\\nTest set accuracy = {(100 * correct_predictions / total_predictions):.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_fCozvFWKLv"
      },
      "source": [
        "## ConvNeXt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ6pr0_6VUFb"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5dDy9zfWb8x"
      },
      "outputs": [],
      "source": [
        "# Create paths for val, train and test (with shuffling the data)\n",
        "dirs = [os.path.join(\"./streetshouses/kaggle_room_street_data/\", path) for path in os.listdir(\"./streetshouses/kaggle_room_street_data/\")]\n",
        "\n",
        "all_files = []\n",
        "\n",
        "for dir_path in dirs:\n",
        "    files = [os.path.join(dir_path, file) for file in os.listdir(dir_path)]\n",
        "    all_files.extend(files)\n",
        "\n",
        "train_paths, test_paths = train_test_split(all_files, train_size=0.9, random_state=42, shuffle=True)\n",
        "train_paths, val_paths = train_test_split(train_paths, train_size=0.78, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl7SFLYHXglL"
      },
      "outputs": [],
      "source": [
        "train_ds = StreetAndHousesDataset(files=train_paths, transform=transforms_train)\n",
        "val_ds = StreetAndHousesDataset(files=val_paths, transform=transforms_val)\n",
        "test_ds = StreetAndHousesDataset(files=test_paths, transform=transforms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFYLdKbuXjty"
      },
      "outputs": [],
      "source": [
        "IN_CHANNELS = 3\n",
        "N_CLASSES = 13\n",
        "\n",
        "convnext_model = tv.models.convnext_base(weights=\"IMAGENET1K_V1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy-7uuT-YugV"
      },
      "outputs": [],
      "source": [
        "for param in convnext_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfxnFOe4Yyz8"
      },
      "outputs": [],
      "source": [
        "# Add on classifier\n",
        "n_inputs = convnext_model.classifier[2].in_features\n",
        "convnext_model.classifier[2] = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 256), nn.GELU(), nn.Dropout(0.4),\n",
        "    nn.Linear(256, N_CLASSES), nn.Softmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOgAipSoY5xi"
      },
      "outputs": [],
      "source": [
        "convnext_model = convnext_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf9obso9Y7oC",
        "outputId": "6813339f-7d87-467f-b0ae-9ffbc3d1b3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "87,832,205 total parameters.\n",
            "265,741 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in convnext_model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in convnext_model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4U64dF_Y9bK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 5e-5\n",
        "WEIGHT_DECAY = 1e-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Zd3O9XZG34"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(dataset=val_ds, batch_size=BATCH_SIZE)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV3nt6_AZIiJ"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(convnext_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwW8IZniZPMB"
      },
      "outputs": [],
      "source": [
        "# Additional ConvNeXt augmentations\n",
        "cutmix = v2.CutMix(num_classes=N_CLASSES)\n",
        "mixup = v2.MixUp(num_classes=N_CLASSES)\n",
        "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_WI_nnaZR0H"
      },
      "outputs": [],
      "source": [
        "best_val_loss = 1e7\n",
        "train_losses = list()\n",
        "val_losses = list()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Train\n",
        "  convnext_model.train()\n",
        "  train_loss = 0.0\n",
        "  for batch in tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{EPOCHS}\", ncols=100):\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = convnext_model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  # Validate\n",
        "  convnext_model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(val_dl, desc=\"Validation\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = convnext_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "  lr_scheduler.step()\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(convnext_model.state_dict(), \"./convnext-streetsandhouses.pt\")\n",
        "\n",
        "  train_losses.append(train_loss / len(train_dl))\n",
        "  val_losses.append(val_loss / len(val_dl))\n",
        "\n",
        "  accuracy = 100 * correct_predictions / total_predictions\n",
        "  print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss / len(train_dl):.4f}, Validation Loss: {val_loss / len(val_dl):.4f}, Validation Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtelG4yJa3NN",
        "outputId": "ef06851d-aff6-4430-8f0a-4311ddf01b9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|████████████████████████████████████████████████████| 141/141 [00:17<00:00,  8.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy = 69.4629%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on Test set\n",
        "convnext_model.eval()\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dl, desc=\"Testing\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = convnext_model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"\\nTest set accuracy = {(100 * correct_predictions / total_predictions):.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrHJnDnTJ9mb"
      },
      "source": [
        "## ConvNeXt V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skz8BYWDJ9mb"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "transforms_val = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize(size=(224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwNL3EEKJ9mc"
      },
      "outputs": [],
      "source": [
        "# Create paths for val, train and test (with shuffling the data)\n",
        "dirs = [os.path.join(\"./streetshouses/kaggle_room_street_data/\", path) for path in os.listdir(\"./streetshouses/kaggle_room_street_data/\")]\n",
        "\n",
        "all_files = []\n",
        "\n",
        "for dir_path in dirs:\n",
        "    files = [os.path.join(dir_path, file) for file in os.listdir(dir_path)]\n",
        "    all_files.extend(files)\n",
        "\n",
        "train_paths, test_paths = train_test_split(all_files, train_size=0.9, random_state=42, shuffle=True)\n",
        "train_paths, val_paths = train_test_split(train_paths, train_size=0.78, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X92omWPsJ9mv"
      },
      "outputs": [],
      "source": [
        "IN_CHANNELS = 3\n",
        "N_CLASSES = 13\n",
        "\n",
        "convnextv2_model = ConvNextV2ForImageClassification.from_pretrained(\"facebook/convnextv2-base-1k-224\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBVW0NkLJ9mw"
      },
      "outputs": [],
      "source": [
        "for param in convnextv2_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAOdqQ3XJ9mw"
      },
      "outputs": [],
      "source": [
        "# Add on classifier\n",
        "n_inputs = convnextv2_model.classifier.in_features\n",
        "convnextv2_model.classifier = nn.Sequential(\n",
        "    nn.Linear(n_inputs, 256), nn.GELU(), nn.Dropout(0.4),\n",
        "    nn.Linear(256, N_CLASSES), nn.Softmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s6M25fzJ9mw"
      },
      "outputs": [],
      "source": [
        "convnextv2_model = convnextv2_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjpdSzvJ9mw",
        "outputId": "3d354535-bdd4-421a-e4e7-df7b88bbf46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "87,958,541 total parameters.\n",
            "265,741 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in convnextv2_model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in convnextv2_model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmlXb02KJ9mx"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 6.25e-4\n",
        "WEIGHT_DECAY = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APaos1fDJ9mx"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(dataset=val_ds, batch_size=BATCH_SIZE)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8p-7zuCJ9mx"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(convnextv2_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z--q80yrJ9mx"
      },
      "outputs": [],
      "source": [
        "# Additional ConvNeXt augmentations\n",
        "cutmix = v2.CutMix(num_classes=N_CLASSES)\n",
        "mixup = v2.MixUp(alpha=0.8, num_classes=N_CLASSES)\n",
        "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6loMaeoLJ9mz"
      },
      "outputs": [],
      "source": [
        "best_val_loss = 1e7\n",
        "train_losses = list()\n",
        "val_losses = list()\n",
        "\n",
        "for epoch in range(EPOCHS - 17):\n",
        "  # Train\n",
        "  convnextv2_model.train()\n",
        "  train_loss = 0.0\n",
        "  for batch in tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{EPOCHS}\", ncols=100):\n",
        "    inputs, labels = batch\n",
        "    inputs, labels = cutmix_or_mixup(inputs, labels)\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = convnextv2_model(inputs)\n",
        "    loss = criterion(outputs[0], labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  # Validate\n",
        "  convnextv2_model.eval()\n",
        "  val_loss = 0.0\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(val_dl, desc=\"Validation\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = convnextv2_model(inputs)\n",
        "      loss = criterion(outputs[0], labels)\n",
        "      val_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs[0], 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "  lr_scheduler.step()\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(convnextv2_model.state_dict(), \"convnextv2-streetsandhouses.pt\")\n",
        "\n",
        "  train_losses.append(train_loss / len(train_dl))\n",
        "  val_losses.append(val_loss / len(val_dl))\n",
        "\n",
        "  accuracy = 100 * correct_predictions / total_predictions\n",
        "  print(f\"Epoch {epoch + 1}/{EPOCHS}, Train Loss: {train_loss / len(train_dl):.4f}, Validation Loss: {val_loss / len(val_dl):.4f}, Validation Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txTQm0TvJ9mz",
        "outputId": "6da14da4-aa7c-4708-83d8-d3e410313cee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing:   0%|                                                              | 0/141 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|████████████████████████████████████████████████████| 141/141 [00:51<00:00,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set accuracy = 70.2175%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on Test set\n",
        "convnextv2_model.eval()\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dl, desc=\"Testing\", ncols=100):\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = convnextv2_model(inputs)\n",
        "      loss = criterion(outputs[0], labels)\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs[0], 1)\n",
        "      total_predictions += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"\\nTest set accuracy = {(100 * correct_predictions / total_predictions):.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALHgwzPuJ9m0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}